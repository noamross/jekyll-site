<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Noam Ross - R</title>
 <link href="http://www.noamross.net/blog/R.xml" rel="self"/>
 <link href="http://www.noamross.net"/>
 <updated>2015-04-29T14:00:30-07:00</updated>
 <id>http://www.noamross.net</id>
 <author>
   <name>Noam Ross</name>
   <email>noam.ross@gmail.com</email>
 </author>

 
 <entry>
   <title>Visualizing fits, inference, implications of (G)LMMs</title>
   <link href="http://www.noamross.net/blog/2015/4/29/koontz-base-plotting.html"/>
   <updated>2015-04-29T14:00:00-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2015/4/29/koontz-base-plotting</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;A couple of weeks at the &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;Davis R Users’ Group&lt;/a&gt;, &lt;a href=&quot;http://michaeljkoontz.weebly.com/&quot;&gt;Jaime Ashander&lt;/a&gt; gave a presentation on and visualizing and diagnosing GLMs in R. Here’s the video:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/QL4Jqmid0Kw&quot; frameborder=&quot;0&quot; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Jaime wrote up the notes from his talk, including all the code, on his blog &lt;a href=&quot;http://www.ashander.info/posts/2015/04/D-RUG-mixed-effects-viz/&quot;&gt;here&lt;/a&gt;. You can get the raw R Markdown file on github &lt;a href=&quot;https://github.com/ashander/ashander.github.io/blob/content/content/notes/mixedeffects_viz.Rmd&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>An introduction to ggplot with Myfanwy Johnston</title>
   <link href="http://www.noamross.net/blog/2015/3/15/ggplot-tutorial-johnston.html"/>
   <updated>2015-03-15T14:36:00-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2015/3/15/ggplot-tutorial-johnston</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;Last week at the &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;Davis R Users’ Group&lt;/a&gt;, &lt;a href=&quot;http://biotelemetry.ucdavis.edu/pages/bio_Johnston.asp&quot;&gt;Myfanwy Johnston&lt;/a&gt; gave an introduction to the powerful and ubiquitous ggplot2 package for plotting in R. See below for the screencast and her particularly enlightening figure of how ggplot’s syntax and conceptual approach. Myfanwy also placed all her slides, code, and links to more ggplot resources in &lt;a href=&quot;https://github.com/Myfanwy/ggplot2Intro&quot;&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/SaJCKpYX5Lo&quot; frameborder=&quot;0&quot; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;(&lt;em&gt;In a D-RUG first, there was an actual small fire that occurred between ~23:10 - 25:40. No graphing took place in this interval.&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://raw.githubusercontent.com/Myfanwy/ggplot2Intro/master/figures/ggplot_structure.png&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/Myfanwy/ggplot2Intro/master/figures/ggplot_structure.png&quot; alt=&quot;https://raw.githubusercontent.com/Myfanwy/ggplot2Intro/master/figures/ggplot_structure.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Making Maps in R with Ryan Peek and Michele Tobias</title>
   <link href="http://www.noamross.net/blog/2015/2/20/mapping-in-R-peek-tobias.html"/>
   <updated>2015-02-20T14:31:00-08:00</updated>
   <id>hhttp://www.noamross.net/blog/2015/2/20/mapping-in-R-peek-tobias</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;Today at the &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;Davis R Users’ Group&lt;/a&gt;, &lt;a href=&quot;http://ucdavis.academia.edu/RyanPeek&quot;&gt;Ryan Peek&lt;/a&gt; and &lt;a href=&quot;https://sites.google.com/site/mtobiasresearch/&quot;&gt;Michele Tobias&lt;/a&gt; gave an introduction to making maps in R. Here’s the webcast:&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/7wNkCeE9SCU&quot; frameborder=&quot;0&quot; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;(Pardon the little scuffle at the beginning and as we switched computers halfway through. Still getting the hang of hangouts.)&lt;/p&gt;
&lt;h3 id=&quot;resources&quot;&gt;Resources:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Download all of Ryan’s code and HTML files &lt;a href=&quot;http://www.noamross.net/files/makingmaps.zip&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;See Michele’s slides on Slideshare &lt;a href=&quot;http://www.slideshare.net/MicheleTobias/leafletr&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Code for Michele’s example maps in &lt;a href=&quot;https://github.com/MicheleTobias/maps&quot;&gt;her GitHub. repository&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Carl Boettiger on accessing online data with ROpenSci</title>
   <link href="http://www.noamross.net/blog/2015/1/30/boettiger-ropensci.html"/>
   <updated>2015-01-30T12:40:00-08:00</updated>
   <id>hhttp://www.noamross.net/blog/2015/1/30/boettiger-ropensci</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;*Today, &lt;a href=&quot;http://www.carlboettiger.info/&quot;&gt;Carl Boettiger&lt;/a&gt; gave a tutorial on the &lt;a href=&quot;http://ropensci.org/&quot;&gt;ROpenSci project&lt;/a&gt; and how to use their many packages to connect to online data repositories to retrieve and up deposit data. Here’s our screencast of the talk.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/JNVRxq-hS9M&quot; frameborder=&quot;0&quot; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;All the code from this talk is available at this &lt;a href=&quot;https://github.com/ropensci/workshops-davis-2015-01&quot;&gt;github repository&lt;/a&gt;, and you can download it as a *.zip file &lt;a href=&quot;https://github.com/ropensci/workshops-davis-2015-01/archive/gh-pages.zip&quot;&gt;here&lt;/a&gt;. Thanks to Carl for for a great session and the ROpenSci team for their work!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Tim Bowles on multivariate stats with vegan</title>
   <link href="http://www.noamross.net/blog/2014/12/9/bowles-vegan.html"/>
   <updated>2014-12-09T19:01:00-08:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/12/9/bowles-vegan</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;&lt;em&gt;Today, &lt;a href=&quot;http://ucanr.edu/sites/Jackson_Lab/Tim_Bowles/&quot;&gt;Tim Bowles&lt;/a&gt; gave this presentation on the &lt;a href=&quot;http://cran.r-project.org/web/packages/vegan/index.html&quot;&gt;vegan&lt;/a&gt; package to the &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;Davis R Users’ Group&lt;/a&gt;. The screencast and slides are below. You can also download Tim’s RStudio project with all the code, data, figures, and slides presented &lt;a href=&quot;https://dl.dropboxusercontent.com/u/3356641/blogstuff/vegan%20tutorial.zip&quot;&gt;here&lt;/a&gt;. Thanks to Tim for a great session!&lt;/em&gt;&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/BEldn3BmqW0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;br/&gt; &lt;br/&gt;&lt;/p&gt;
&lt;div class=&quot;rpres&quot; style=&quot;padding-bottom: 110%;&quot;&gt;
&lt;iframe src=&quot;https://dl.dropboxusercontent.com/u/3356641/blogstuff/vegan-D-RUG.html&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Ongoing learning with user groups</title>
   <link href="http://www.noamross.net/blog/2014/11/10/usergroups.html"/>
   <updated>2014-11-10T12:00:00-08:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/11/10/usergroups</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;&lt;em&gt;Cross-posted from the &lt;a href=&quot;http://software-carpentry.org/blog/2014/11/users-groups-for-ongoing-learning.html&quot;&gt;Software Carpentry Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For the past two years I’ve run the &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;UC Davis R Users’ Group&lt;/a&gt; (D-RUG). In this post, I’ll (1) outline the structure of D-RUG, and (2) summarize some lessons learned, and (3) discuss how such users’ groups could act to support and complement SWC’s workshops. Per &lt;a href=&quot;http://forum.mozillascience.org/t/new-member-introductions/30/22&quot;&gt;Bill’s suggestion&lt;/a&gt;, we could discuss the role of users group at a future &lt;a href=&quot;http://mozillascience.org/instructor-hangouts-landing-this-friday/&quot;&gt;instructor hangout&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;D-RUG was created with similar motivations as SWC - to help scientists learn computing skills. Unlike SWC workshops, our model has been “everyone teaches everyone” rather than “instructor –&amp;gt; learner”. I saw that science graduate students at Davis increasingly needed to use R and similar tools in both their coursework and research, and there was a fair bit of knowledge dispersed among students and faculty in the university. But there was little training on programming, and no forum to share our knowledge.&lt;/p&gt;
&lt;p&gt;Our users are primarily graduate students and postdocs from across the university, though they’re skewed towards ecology and related fields. Most have no training in computer science or programming. They take up R either for coursework or when a specific research task demands it. So they are pretty much in the same place as most SWC Workshop students. We try to maintain low barriers to entry for these students.&lt;/p&gt;
&lt;p&gt;Our basic operating principle is maintaining &lt;em&gt;low barriers to entry&lt;/em&gt; for &lt;em&gt;users of all skill levels.&lt;/em&gt; That means meeting students where they are in terms of their tools and needs, and making it as easy as possible for volunteers to pitch in.&lt;/p&gt;
&lt;h2 id=&quot;basic-elements-of-the-users-group&quot;&gt;Basic elements of the Users’ Group&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Work sessions&lt;/strong&gt;: We have weekly, 2-hour co-work sessions where users come to work on their own projects and get help.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Talks and tutorials&lt;/strong&gt;: About every other week, the first half of our work sessions is dedicated to a presentation. These are mainly tutorials on tools in R. Sometimes they are “show-and-tell” where a user presents an analysis for feedback. Most speakers walk through a script on a large screen, and Q &amp;amp; A takes up half of the time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A Q &amp;amp; A listserv&lt;/strong&gt;: We use Google Groups to manage a listserv where people can ask questions, which is especially helpful for our many users who can’t attend the weekly sessions.&lt;/p&gt;
&lt;p&gt;Global fora, like the &lt;a href=&quot;http://www.r-project.org/mail.html&quot;&gt;R mailing lists&lt;/a&gt; or &lt;a href=&quot;http://stackoverflow.com/questions/tagged/r&quot;&gt;Stack Overflow&lt;/a&gt;, are great, but in order to scale they need pretty strict rules that are challenging for beginners. Many beginners don’t yet know how to frame questions to get good answers. Since our listserv is small-scale, new users can ask open-ended questions and expect responses more helpful than “RTFM.”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A website and blog&lt;/strong&gt;: Our blog mostly serves as a way to post &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html#d-rug-tutorials-from-our-meetings&quot;&gt;materials from our talks&lt;/a&gt;, usually &lt;code&gt;Rmd&lt;/code&gt; scripts or slides. More recently we have been broadcasting our tutorials with Google Hangouts on Air and posting those videos, as well.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;some-lessons-learned&quot;&gt;Some lessons learned&lt;/h2&gt;
&lt;p&gt;After 2 years, D-RUG has proved a successful. A typical meeting brings 5-15 members, usually evenly split between regulars and those who come just when they have questions. Attendance tends to be higher towards the beginning of the term and when we have speakers. A fair number of on-campus (and LOTS of off-campus users) view the tutorials online.400 members have signed up for the listserv. 10-20% of these are active posters, and most questions get answered in a day or so.Most importantly, I’ve seen many users arrive with little or no experience, and go on be our most useful helpers and give some of our best tutorials.&lt;/p&gt;
&lt;p&gt;Here a few of the lessons I’ve learned in running D-RUG:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;One major challenge is keeping enough advanced users engaged so that they can be a resource for beginners. Advanced users who attend work sessions can expect to spend about 50% of their time answering questions of others.&lt;/p&gt;
&lt;p&gt;The listserv is a low-commitment way for advanced users to help, and is even our advanced users ask questions on it sometimes. Our &lt;a href=&quot;http://www.revolutionanalytics.com/r-user-group-sponsorship-program&quot;&gt;sponsors at Revolution Analytics&lt;/a&gt; send us a box of schwag each year - I use these as prizes to recognize helpful volunteers.&lt;/p&gt;
&lt;p&gt;Users who started off as beginners but have learned a lot through D-RUG tend to be our most dedicated volunteers.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There’s a trade-off between running D-RUG as a meeting where people regularly give talks, and a space where people come to work.  I found a pretty good medium having weekly 2-hr work sessions, with talks every other week for half the session during the school year. More people tend to come to those sessions with talks.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is constant work wrangling people to give talks, and one doesn’t want to burden advanced users already volunteering their time with too many requests to give tutorials.  It’s good to encourage people who are learning a new topic to give talks on things they just learned.  Also, encourage them to just walk through a script rather than make slides.  It’s less work for the presenter, and the script is more useful to others afterwards than slides.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Users are much more likely to be interested in &lt;em&gt;applications&lt;/em&gt; rather than programming topics. Talks on topics like “How to do AIC model comparison” and “How to prepare plots for publication” have been much more well attended (and heavily trafficked on the blog) than ones on topics like “speeding up code.” This is partially a function of our membership (mostly empirical ecologists, biologists, and social scientists).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It takes time to build self-sustaining community. For our first year, I had to monitor the listserv to make sure questions didn’t go unanswered, and I ran every work session and bugged power users to attend. Now the listserv runs itself and we have enough regulars at our work sessions. We would like to find some arrangements to help institutionalize the group more, though. One possibility is having professors or TAs for courses using R to hold office hours at D-RUG.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Food helps. We have snacks paid for by our &lt;a href=&quot;http://www.revolutionanalytics.com/r-user-group-sponsorship-program&quot;&gt;sponsor&lt;/a&gt;. A lot of expert users and professors stop in for a mid-afternoon sugar infusion, and end up answering questions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;users-groups-as-a-complementary-tool-for-swc&quot;&gt;Users’ Groups as a complementary tool for SWC&lt;/h2&gt;
&lt;p&gt;Users’ groups have the potential to be a complementary tool to SWC workshops. We recruited a number of new members at the &lt;a href=&quot;http://bernhardkonrad.github.io/2014-06-16-davis/&quot;&gt;June SWC Workshop at Davis&lt;/a&gt;, and they’ve been able to practice and build those skills at our work sessions. Users’ groups also may be a good forum to stay connected to and follow up with learners.&lt;/p&gt;
&lt;p&gt;Beginners need a minimum amount of knowledge to take advantage of D-RUG, which can be provided by SWC workshops. D-RUG doesn’t have the resources or structure to teach those beginners from scratch. I sometimes point new users who show up with no experience to an appropriate online self-taught course, and encourage them do the work at our sessions where they can get support. If these members attend a SWC workshop, they will know enough to get started, and to support each other.&lt;/p&gt;
&lt;p&gt;The D-RUG model is fairly easy to replicate. Daniel Hocking at the University of New Hampshire has &lt;a href=&quot;http://nhusers.com/&quot;&gt;created a similar group&lt;/a&gt;. Anyone with the skill level of a typical SWC workshop helper can probably run a users’ group, though it does require a certain amount of time and skill at recruiting on-campus.&lt;/p&gt;
&lt;p&gt;I’d like to hear from others who have similar or alternative models. How can these groups connect with SWC to build an ongoing community of learners?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>More ESA 2014 Program Text-Mining: Topics as Communities</title>
   <link href="http://www.noamross.net/blog/2014/8/22/topicmodeling.html"/>
   <updated>2014-08-22T16:07:42-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/8/22/topicmodeling</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;In &lt;a href=&quot;http://www.noamross.net/blog/2014/7/24/esacorpuscompare.html&quot;&gt;my first pass at text analysis of the ESA program&lt;/a&gt;, I looked at how the frequency of words used in the ESA program differed from last year to this year. There are much more sophisticated ways at looking at word use in text, though, and I began to dive into the text-mining literature to find other ways to draw insight from ESA abstracts.&lt;/p&gt;
&lt;p&gt;One method I found is &lt;em&gt;topic modeling&lt;/em&gt; using &lt;a href=&quot;http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation&quot;&gt;latent Dirichlet allocation&lt;/a&gt; (LDA). Using this method, a number of “topics” are identified, each consisting of groups of words occur together. Documents are treated as linear mixtures of these topics. Carson Sievert recently wrote a &lt;a href=&quot;http://ropensci.org/blog/2014/04/16/topic-modeling-in-R/&quot;&gt;great blog post on the ROpenSci blog&lt;/a&gt; about this and his package with Kenneth E. Shirley, &lt;a href=&quot;https://github.com/cpsievert/LDAvis&quot;&gt;LDAvis&lt;/a&gt;, which produces interactive visualizations of of LDA models.&lt;/p&gt;
&lt;p&gt;I had trouble wrapping my head around LDA at first, but on Wednesday at ESA, Dave Harris &lt;a href=&quot;https://twitter.com/davidjayharris/status/499660097715699713&quot;&gt;alerted me&lt;/a&gt; to an &lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper46683.html&quot;&gt;awesome talk&lt;/a&gt; by &lt;a href=&quot;http://sfrc.ufl.edu/people/faculty/valle/&quot;&gt;Denis Valle&lt;/a&gt;. Valle showed that LDA can be used to model assemblages of species. In this case, we model communities of co-occurring species, rather than topics of co-occurring words, and rather than documents, we have sample locations. He demonstrated the method on USFS Forest Inventory and Analysis data, showing distinct communities of trees in Eastern U.S. forests. Valle’s talk made LDA much clearer to me, and showed that LDA could be an alternative to other methods of community analysis such as ordination. I’m looking forward to the forthcoming paper.&lt;/p&gt;
&lt;p&gt;Back to the ESA program: LDA requires that we specify the number of topics, and it then allocates words among those topics. So I fit a series of models and used AIC to determine the best fit:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/LDA_AIC.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The model with the lowest AIC breaks the ESA program into 56 different topics. We can explore this model with an interactive visualization created by LDAvis:&lt;/p&gt;
&lt;div style=&quot;margin-left:-200px; margin-right:-200px&quot;&gt;
&lt;iframe src=&quot;http://www.noamross.net/esa_lda/index.html&quot; width=&quot;1200&quot; height=&quot;700&quot;&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;On the left, topics are represented as numbered circles, with the number representing their rank (1 = most common topic), and their size representing relative frequency across all abstracts. They are plotted so that similar topics are clustered together and different topics are farther apart.&lt;/p&gt;
&lt;p&gt;Click on any circle and you’ll see a list of the top 30 terms making up that topic on the right. Note that the words are “stemmed” - their suffixes have been removed so as to treat different forms of the same word as a single value. Relative word ranking is a balance between the importance of the word within the topic (red bars) and the frequency of the word across all documents (grey bars). You can adjust this balance using the ‘Lambda’ box on the top-right. Click on any word and you’ll see in what other topics it appears.&lt;/p&gt;
&lt;p&gt;Let’s explore! Clicking on Topic 1, we see very general words that might appear in any abstract. Topic 2 seems to be made up of words related to conservation and planning, showing the importance of this subject in the meeting. But click on “cost” in Topic 2 and you’ll see that this term is important in several other topics: 23 (words involving life-history), 36 (plant-water relations), and 47 (behavioral ecology). Topic 3 consists of general words having to do with methods, but nearby, topics 10 and 11 consist of words related to data collection and modeling, respectively.&lt;/p&gt;
&lt;p&gt;One interesting observation is that “California” is most frequent in Topic 42, which consists of words related to marine systems, and is also common in 53 (invasions), 38 (fire), and 36 (plant-water relations). I was unsurprised at the last two (especially given fire’s importance in &lt;a href=&quot;http://www.noamross.net/blog/2014/7/24/esacorpuscompare.html&quot;&gt;my last analysis&lt;/a&gt;), but hadn’t realized how California-specific marine topics would be.&lt;/p&gt;
&lt;p&gt;There’s lots more to explore here, though it’s not always easy to interpret. Some topics seem to map well to ecological sub-fields, while others may be driven by concepts and frameworks that are difficult to classify, or even writing style. What patterns do you see that are worth a harder look?&lt;/p&gt;
&lt;p&gt;Code for this analysis is on Github &lt;a href=&quot;https://github.com/noamross/esaprog&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>ESA 2014: Don't Know Much About History...</title>
   <link href="http://www.noamross.net/blog/2014/8/5/nathist.html"/>
   <updated>2014-08-05T08:14:11-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/8/5/nathist</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;After my &lt;a href=&quot;http://www.noamross.net/blog/2014/7/24/esacorpuscompare.html&quot;&gt;last post&lt;/a&gt; text-mining &lt;a href=&quot;http://esa.org/am/&quot;&gt;ESA Annual Meeting&lt;/a&gt; abstracts, &lt;a href=&quot;http://www.nashturley.org/&quot;&gt;Nash Turley&lt;/a&gt; &lt;a href=&quot;https://twitter.com/NashTurley/status/495272858038595587&quot;&gt;was interested&lt;/a&gt; in the presence of the term “natural history” in ESA abstracts. I decided to collect a little more data by including programs back to 2010, giving a five-year data set. Thankfully the program back to 2010 remains in mostly the same format, so it’s easy to pull the data for these additional years.&lt;/p&gt;
&lt;p&gt;Now, not all talks that include natural history concepts will include the term “natural history”&lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; in their abstracts, but it’s frequency may be an indicator of importance, and &lt;em&gt;variation&lt;/em&gt; in use of the term is may yield some insights.&lt;/p&gt;
&lt;p&gt;First, I look at what fraction of abstracts mention “natural history” in each of the last five years at ESA.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/fraction.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Over the past five years, &amp;lt;1% of abstracts at ESA have mentioned natural history. No trend is evident.&lt;/p&gt;
&lt;p&gt;I reported different numbers for 2013 and 2014 in a &lt;a href=&quot;https://twitter.com/noamross/status/492407527238160386&quot;&gt;tweet&lt;/a&gt; last week. These were higher because I counted them by a simple search of the number of occurrences of “natural history” in the whole corpus. This included the &lt;em&gt;affiliation&lt;/em&gt; fields. Many presenters at ESA work at natural history &lt;em&gt;museums&lt;/em&gt; (see &lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper50396.html&quot;&gt;this abstract&lt;/a&gt;, for instance). The above numbers now only include abstracts where “natural history” was in the title or abstract text, and now I count abstracts, not occurrences of the phrase.&lt;/p&gt;
&lt;p&gt;What are these natural history talks about? To examine this, I looked at the word frequency across all five years of abstracts, finding the most frequent terms besides “natural history”.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/wordcountsi.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;For comparison, here are the most common terms across all ESA abstracts this year:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/plot1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Like other abstracts, talks that mention “natural history” have “species” as the most common term. Interestingly, natural history talks don’t use “plant” as frequently - perhaps other terms are used in botanical contexts. Also, there are more relative mentions of “students”, perhaps due to greater links between natural history and education. We can see this pattern in a listing of all the talks for 2014, where we see several talks about education, though there are many fascinating basic science talks, as well:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;Presenter&lt;/th&gt;
&lt;th style=&quot;text-align: left;&quot;&gt;Title/Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Julian D. Olden&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45275.html&quot;&gt;Traits-based approaches and the quest for generality over contingency in ecology&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Terry A. Wheeler&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45504.html&quot;&gt;The other “E”: Entomologists and entomology in (and out) of the Ecological Society of America&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Kimball L. Garrett&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45813.html&quot;&gt;Recent avifaunal change in riparian habitats along the Los Angeles River&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Kirsten Rowell&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45934.html&quot;&gt;Natural History Section&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Shahid Naeem&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45950.html&quot;&gt;Condensation and ignition in ecological research: Making sense of biodiversity’s demise&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Cory Merow&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper46334.html&quot;&gt;Methods for predicting and validating range-wide population dynamics from sparse demographic data&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Fiona M. Soper&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper47409.html&quot;&gt;Coupling graduate mentorship training with undergraduate research in a field context&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Emily M. Harris&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper48283.html&quot;&gt;Participating in the California Naturalist Program: Changes in science and environmental identity&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Teresa K. Heisey&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper48545.html&quot;&gt;Sand County Almanac in the ecology classroom: An active learning approach to teaching about ecology and natural history&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Leighton Reid&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper48621.html&quot;&gt;Conservation psychology: Bat killing in southern Costa Rica&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Kristen R. Treat&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper49217.html&quot;&gt;Variation of Pentaclethra macroloba natural history and genetic structure along an elevational gradient in lowland Costa Rica&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Flavia M. D. Marquitti&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper49277.html&quot;&gt;The role of cheaters on the stability of mutualistic networks&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Melissa Gaste Martinez&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper49484.html&quot;&gt;Bothrops atrox in captivity, change isotopic composition in tissues collected from different environments of the eastern Amazon&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;D. Liane Cochran-Stafira&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper49924.html&quot;&gt;Effects of Metriocnemus knabi predation on Habrotrocha rosa populations in Sarracenia purpurea pitchers&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Emily Hartop&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper50108.html&quot;&gt;Terrestrial insects of los angeles: The great frontier&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Danielle B. Pitt&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper50268.html&quot;&gt;Linking early history of Pterygota to habitat structure: The role of dendritic ecological networks in insect natural history&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Carole L. Hom&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper50330.html&quot;&gt;UC Davis-Howard University EEGAP: Collaborating to broaden participation in ecology and evolution&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;Senay Yitbarek&lt;/td&gt;
&lt;td style=&quot;text-align: left;&quot;&gt;&lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper50363.html&quot;&gt;The role of self-organized spatial patterns in the persistence of weak invasive species: A case study of the invasive ant W. auropunctata&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;I note the third talk in this list is an &lt;a href=&quot;http://eco.confex.com/eco/2014/webprogram/Paper45934.html&quot;&gt;ignite talk&lt;/a&gt; announcing the new ESA natural history section. Perhaps we’ll see the effect of this section next year’s program!&lt;/p&gt;
&lt;p&gt;R code for this post is on &lt;a href=&quot;https://github.com/noamross/esaprog/blob/master/nathist.Rmd&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;Or rather, something close to “natural history”. I searched for the regular expression &lt;code&gt;natur\w+\s+hist&lt;/code&gt;.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>What shall we talk about at ESA?</title>
   <link href="http://www.noamross.net/blog/2014/7/24/esacorpuscompare.html"/>
   <updated>2014-07-24T01:45:15-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/7/24/esacorpuscompare</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;&lt;a href=&quot;http://esa.org/am/&quot;&gt;ESA&lt;/a&gt; is just around the corner, and many of us are gearing up and trying to figure out a &lt;a href=&quot;http://eco.confex.com/eco/2014/schedule/index.cgi&quot;&gt;schedule&lt;/a&gt; to cover all the talks and people we can pack in. ESA is a big conference and there’s far too much for any one person to see. In the end, everyone experiences a &lt;a href=&quot;http://en.wikipedia.org/wiki/Blind_men_and_an_elephant&quot;&gt;different part of the elephant&lt;/a&gt;. However, I thought it would be interesting to take a look at the big picture, and examine the ESA program as a &lt;em&gt;whole&lt;/em&gt; to see what could be learned from it. This is the first of (maybe) several posts where I use some basic text-mining tools to explore the content of the ESA program.&lt;/p&gt;
&lt;p&gt;First, what are the most common terms in the ESA program?&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/plot1.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Few surprises here. “Species” would have been my guess for the top. “Plants” are probably on top because ecologists usually refer to animals by various sub-groups. The rest are fairly ho-hum: ecology and science-y words.&lt;/p&gt;
&lt;p&gt;It’s more interesting to ask how the topics at ESA &lt;em&gt;change&lt;/em&gt; from year to year. Below I show the terms whose use in ESA abstracts changed the most between 2013 to 2014:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/mung.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;This paints a much more interesting picture. The rise of California and the fall of Minnesota make sense given the change in the meeting’s location. But we can see the influence of landscape on topics as well. We see fewer words associated with freshwater ecosystems, prairies, and forests this year, and more associated with fire and other plant systems. Also, we see a difference in the &lt;em&gt;kinds&lt;/em&gt; of ecology in the program. This year there are fewer words like “biomass” and “nutrient” - those common in ecosystem ecology - and more like “pollinator”&lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, “phenology”, and “network” - those associated with the study of species interactions.&lt;/p&gt;
&lt;p&gt;It’s possible that these changes are due to changes in what’s popular in ecology, but it is also likely that many of the concepts captured in these terms - ecosystem, community, and landscape ecology - are influenced by region. After all, an ecosystem perspective is likely to dominate in the Midwest, where an abundance of lakes have been important in the research of freshwater nutrient cycling, and a landscape perspective may be important in California, which has such heterogeneity of habitats. This is a pretty good argument for keeping ESA’s location moving, so that no regional perspective dominates every year.&lt;/p&gt;
&lt;p&gt;These are the biggest &lt;em&gt;changes&lt;/em&gt;, but have the biggest &lt;em&gt;topics&lt;/em&gt; changed? The plot below is similar to that above, but instead of plotting the words with the greatest absolute change, I plot the change of the 50 words that are most common across both years:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;http://dl.dropbox.com/u/3356641/blogstuff/big.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;This is somewhat less clear. If one squints, one could argue that there are more words associated with species interactions, environmental change, and management at the top, and more words associated with forests at the bottom. Words in the middle (“ecology”, “community”) are consistently popular across both years. Finally, perhaps significance is falling out of fashion?&lt;/p&gt;
&lt;p&gt;That’s just a quick first pass. I haven’t yet thought much about how one models these data to understand effect sizes and significance. I welcome suggestions for further analyses and better ways to plot/organize this data. Check out &lt;a href=&quot;https://github.com/noamross/esaprog&quot;&gt;this repository on github&lt;/a&gt; for the code that generated these plots and how to grab the ESA program text for your own use. See you in a few weeks!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;P.S.&lt;/strong&gt; While messing with the ESA program text, I also created &lt;a href=&quot;http://twitter.com/esa_titles&quot;&gt;@esa_titles&lt;/a&gt;, a twitter account that re-mixes ESA talk titles. Have a look for talks you wish you could see. :)&lt;/p&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;“pollinia” is a stand-in for all pollination-related words here, as I applied &lt;a href=&quot;http://en.wikipedia.org/wiki/Stemming&quot;&gt;stemming&lt;/a&gt; to the text.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>Vectorization in R: Why?</title>
   <link href="http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html"/>
   <updated>2014-04-16T11:05:35-07:00</updated>
   <id>hhttp://www.noamross.net/blog/2014/4/16/vectorization-in-r--why</id>
   <content type="html">&lt;head&gt;
  &lt;style type=&quot;text/css&quot;  media=&quot;all&quot;&gt;
    table tbody {border-top:2px; border-bottom:2px;}
    table thead {border-bottom:1px;}
  &lt;/style&gt;
&lt;/head&gt; &lt;p&gt;&lt;em&gt;Here are my notes from a recent talk I gave on vectorization at a &lt;a href=&quot;http://www.noamross.net/davis-r-users-group.html&quot;&gt;Davis R Users’ Group&lt;/a&gt; meeting. Thanks to &lt;a href=&quot;https://twitter.com/vsbuffalo&quot;&gt;Vince Buffalo&lt;/a&gt;, &lt;a href=&quot;http://twitter.com/johnmyleswhite&quot;&gt;John Myles White&lt;/a&gt;, and &lt;a href=&quot;http://twitter.com/hadleywickham&quot;&gt;Hadley Wickham&lt;/a&gt; for their input as I was preparing this. Feedback welcome!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Beginning R users are often told to “vectorize” their code. Here, I try to explain &lt;em&gt;why&lt;/em&gt; vectorization can be advantageous in R by showing how R works under the hood.&lt;/p&gt;
&lt;p&gt;Now, remember, &lt;a href=&quot;http://c2.com/cgi/wiki?PrematureOptimization&quot;&gt;premature optimization is the root of all evil (Knuth)&lt;/a&gt;. Don’t start re-writing your code unless the time saved is going to be worth the time invested. &lt;a href=&quot;http://www.noamross.net/blog/2013/4/25/faster-talk.html&quot;&gt;Other approaches, like finding a bigger machine or parallelization&lt;/a&gt;, could give you more bang for the buck in terms of programming time. But if you understand the nuts and bolts of vectorization in R, it may help you write shorter, simpler, safer, and yes, faster code in the first place.&lt;/p&gt;
&lt;p&gt;First, let’s acknowledge that vectorization can seem like voodoo. Consider a two math problems, one vectorized, and one not:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} + 
\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} =
\begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\begin{aligned}
1 + 1 = 2 \\
2 + 2 = 4 \\
3 + 3 = 6
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Why on earth should these take a different amount of time to calculate? Linear algebra isn’t magic. In both cases there are three addition operations to perform. So what’s up?&lt;/p&gt;
&lt;h2 id=&quot;what-on-earth-is-r-actually-doing&quot;&gt;1. What on earth is R actually doing?&lt;/h2&gt;
&lt;p&gt;R is a &lt;em&gt;high-level&lt;/em&gt;, &lt;em&gt;interpreted&lt;/em&gt; computer language. This means that R takes care of a lot of basic computer tasks for you. For instance, when you type&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;    i &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;5.0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you &lt;em&gt;don’t&lt;/em&gt; have to tell your computer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;That “5.0” is a floating-point number&lt;/li&gt;
&lt;li&gt;That “i” should store numeric-type data&lt;/li&gt;
&lt;li&gt;To find a place in memory for to put “5”&lt;/li&gt;
&lt;li&gt;To register “i” as a pointer to that place in memory&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You also don’t have to convert &lt;code&gt;i &amp;lt;- 5.0&lt;/code&gt; to binary code. That’s done automatically when you hit ‘Enter’.&lt;/p&gt;
&lt;p&gt;When you then type&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;i &amp;lt;-&lt;span class=&quot;st&quot;&gt; &amp;quot;foo&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you don’t have to tell the computer that &lt;code&gt;i&lt;/code&gt; no longer stores an integer but a series of characters that form a &lt;em&gt;string&lt;/em&gt;, to store “f”, “o”, and “o”, consecutively, etc.&lt;/p&gt;
&lt;p&gt;R figures these things on it’s own, on the fly, as you type commands or source them from a file. This means that running a command in R takes a &lt;em&gt;relatively&lt;/em&gt; longer time than it might in a lower-level language, such as C. If I am writing in C, I might write&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;int i
i =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tells the computer the &lt;code&gt;i&lt;/code&gt; will store data of the type &lt;code&gt;int&lt;/code&gt; (integers), and assign the value 5 to it. If I try to assign 5.5 to it, something will go wrong. Depending on my set-up, it might throw an error, or just silently assign 5 to &lt;code&gt;i&lt;/code&gt;. But C doesn’t have to figure out what type of data is is represented by &lt;code&gt;i&lt;/code&gt; and this is part of what makes it faster.&lt;/p&gt;
&lt;p&gt;Here’s another example. If, in R, you type:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;2L +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;3.5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The computer asks:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“OK, what’s the first thing?”&lt;/p&gt;
&lt;p&gt;“An integer”&lt;/p&gt;
&lt;p&gt;“The second thing?”&lt;/p&gt;
&lt;p&gt;“A a floating-point number”&lt;/p&gt;
&lt;p&gt;“Do we have a way to deal with adding an integer and a floating-point number?”&lt;/p&gt;
&lt;p&gt;“Yes! Convert the integer to a floating-point number, then add the two floating point numbers”&lt;/p&gt;
&lt;p&gt;[converts integer]&lt;/p&gt;
&lt;p&gt;[finds a place in memory for the answer]&lt;/p&gt;
&lt;p&gt;etc.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If R were a &lt;em&gt;compiled&lt;/em&gt; computer language, like C or FORTRAN, much of this “figuring out” would be accomplished during the compilation step, not when the program was run. Compiled programs are translated into binary computer language after they are written, but before they are run, and this occurs over the &lt;em&gt;whole program&lt;/em&gt;, rather than line-by-line. This allows the compiler to organize the binary machine code in an optimal way for the computer to interpret.&lt;/p&gt;
&lt;p&gt;What does this have to do with vectorization in R? Well, &lt;strong&gt;many R functions are actually written in a a compiled language&lt;/strong&gt;, such as C, C++, and FORTRAN, and have a small R “wrapper”. For instance, when you inspect the code for &lt;code&gt;fft&lt;/code&gt;, the fast Fourier transform, you see&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;fft
function (z, &lt;span class=&quot;dt&quot;&gt;inverse =&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;) 
&lt;span class=&quot;kw&quot;&gt;.Call&lt;/span&gt;(C_fft, z, inverse)
&amp;lt;bytecode:&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0x7fc261e1b910&lt;/span&gt;&amp;gt;
&lt;span class=&quot;er&quot;&gt;&amp;lt;&lt;/span&gt;environment:&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;namespace:stats&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R is passing the data onto a C function called &lt;code&gt;C_fft&lt;/code&gt;. You’ll see this in many R functions. If you look at their source code, it will include &lt;code&gt;.C()&lt;/code&gt;, &lt;code&gt;.Call()&lt;/code&gt;, or sometimes &lt;code&gt;.Internal()&lt;/code&gt; or &lt;code&gt;.Primitive()&lt;/code&gt;. These means R is calling a C, C++, or FORTRAN program to carry out operations. However, R still has to interpret the input of the function before passing it to the compiled code. In &lt;code&gt;fft()&lt;/code&gt; the compiled code runs only &lt;em&gt;after&lt;/em&gt; R figures out the data type in &lt;code&gt;z&lt;/code&gt;, and also whether to use the default value of &lt;code&gt;inverse&lt;/code&gt;. The compiled code is able to run faster than code written in pure R, because the “figuring out” stuff is done first, and it can zoom ahead without the “translation” steps that R needs.&lt;/p&gt;
&lt;p&gt;If you need to run a function over all the values in a vector, you could pass a whole vector through the R function to the compiled code, or you could call the R function repeatedly for each value. If you do the latter, R has to do the “figuring out” stuff, as well as the translation, &lt;em&gt;each time&lt;/em&gt;. But if you call it once, with a vector, the “figuring out” part happens just once.&lt;/p&gt;
&lt;p&gt;Inside the C or FORTRAN code, vectors are actually processed using loops or a similar construct. This is inevitable; somehow the computer is going to need to operate on each element of your vector. Since this occurs in the compiled code, though, without the overhead of R functions, this is much faster.&lt;/p&gt;
&lt;p&gt;Another important component of the speed of vectorized operations is that vectors in R are &lt;em&gt;typed&lt;/em&gt;. Despite all of its flexibility, R does have some restrictions on what we can do. All elements of a vector must be the same data type. If I try to do this&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;a &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;ot&quot;&gt;FALSE&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;quot;hello&amp;quot;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I get&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;a
[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &lt;span class=&quot;st&quot;&gt;&amp;quot;1&amp;quot;&lt;/span&gt;     &lt;span class=&quot;st&quot;&gt;&amp;quot;2&amp;quot;&lt;/span&gt;     &lt;span class=&quot;st&quot;&gt;&amp;quot;FALSE&amp;quot;&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;hello&amp;quot;&lt;/span&gt;
&amp;gt;&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;class&lt;/span&gt;(a)
[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;] &lt;span class=&quot;st&quot;&gt;&amp;quot;character&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R converts all my data to characters. It can’t handle a vector with different data types.&lt;/p&gt;
&lt;p&gt;So when R needs to perform an operation like&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;) +&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;c&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R only has to ask what types of data are in &lt;em&gt;each vector&lt;/em&gt; (2) rather than &lt;em&gt;each element&lt;/em&gt; (6).&lt;/p&gt;
&lt;p&gt;One consequence of all this is that fast R code is short. If you can express what you want to do in R in a line or two, with just a few function calls that are actually calling compiled code, it’ll be more efficient than if you write long program, with the added overhead of many function calls. This is not the case in all other languages. Often, in compiled languages, you want to stick with lots of very simple statements, because that allows the compiler to figure out the most efficient translation of the code.&lt;/p&gt;
&lt;h2 id=&quot;everything-is-a-vector&quot;&gt;2. Everything is a vector&lt;/h2&gt;
&lt;p&gt;In R &lt;em&gt;everything&lt;/em&gt; is a vector. To quote Tim Smith in &lt;a href=&quot;http://tim-smith.us/arrgh/&quot;&gt;“aRrgh: a newcomer’s (angry) guide to R”&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All naked numbers are double-width floating-point atomic vectors of length one. You’re welcome.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This means that, in R, typing “6” tells R something like&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&amp;lt;start vector, type=numeric, length=&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&amp;gt;&lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;&amp;lt;end vector&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While in other languages, “6” might just be&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;&amp;lt;numeric&amp;gt;&lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, while in other languages, it might be more efficient to express something as a single number rather than a length-one vector, in R this is impossible. There’s no &lt;em&gt;advantage&lt;/em&gt; to NOT organizing your data as vector. In other languages, short vectors might be better expressed as scalars.&lt;/p&gt;
&lt;h2 id=&quot;linear-algebra-is-a-special-case&quot;&gt;3. Linear algebra is a special case&lt;/h2&gt;
&lt;p&gt;Linear algebra is one of the core functions of a lot of computing, so there are highly optimized programs for linear algebra. Such a program is called a BLAS - basic linear algebra system. R, and a lot of other software, relies on these specialized programs and outsources linear algebra to them. A BLAS is generally designed to be highly efficient and has things like built-in parallel processing, hardware-specific implementation, and a host of other tricks. So if your calculations can be expressed in actual linear algebra terms, such as matrix multiplication, than it is almost certainly faster to vectorize them because the BLAS will be doing most of the heavy lifting.&lt;/p&gt;
&lt;p&gt;There are faster and slower linear algebra libraries, and you can install new ones on your computer and tell R to use them instead of the defaults. This used to be like putting a new engine in your car, but &lt;a href=&quot;http://moderntoolmaking.blogspot.com/2013/07/for-faster-r-on-mac-use-veclib.html&quot;&gt;it’s gotten considerably easier&lt;/a&gt;. For certain problems, a shiny new BLAS can considerably speed up code, but results vary depending on the specific linear algebra operations you are using.&lt;/p&gt;
&lt;h2 id=&quot;functionals-pre-allocating-memory-avoiding-side-effects.&quot;&gt;4. Functionals: Pre-allocating memory, avoiding side effects.&lt;/h2&gt;
&lt;p&gt;There are a whole family of functions in R called &lt;em&gt;functionals&lt;/em&gt;, or &lt;code&gt;apply&lt;/code&gt; functions, which take vectors (or matrices, or lists) of values and apply arbitrary functions to each. Because these can use &lt;em&gt;arbitrary&lt;/em&gt; functions, they are NOT compiled. Functionals mostly are written in pure R, and they speed up code only in certain cases.&lt;/p&gt;
&lt;p&gt;One operation that is slow in R, and somewhat slow in all languages, is memory allocation. So one of the slower ways to write a &lt;code&gt;for&lt;/code&gt; loop is to resize a vector repeatedly, so that R has to re-allocate memory repeatedly, like this:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;j &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;
for (i in &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;) {
    j[i] =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, in each repetition of the &lt;code&gt;for&lt;/code&gt; loop, R has to re-size the vector and re-allocate memory. It has to find the vector in memory, create a new vector that will fit more data, copy the old data over, insert the new data, and erase the old vector. This can get very slow as vectors get big.&lt;/p&gt;
&lt;p&gt;If one pre-allocates a vector that fits all the values, R doesn’t have to re-allocate memory each iteration, and the results can be much faster. Here’s how you’d do that for the above case:&lt;/p&gt;
&lt;pre class=&quot;sourceCode r&quot;&gt;&lt;code class=&quot;sourceCode r&quot;&gt;j &amp;lt;-&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;rep&lt;/span&gt;(&lt;span class=&quot;ot&quot;&gt;NA&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
for (i in &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;) {
    j[i] =&lt;span class=&quot;st&quot;&gt; &lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;apply&lt;/code&gt; or &lt;code&gt;plyr::*ply&lt;/code&gt; functions all actually have &lt;code&gt;for&lt;/code&gt; loops inside, but they automatically do things like pre-allocating vector size so you don’t screw it up. This is the main reason that they can be faster.&lt;/p&gt;
&lt;p&gt;Another thing that “ply” functions help with is avoiding what are known as &lt;em&gt;side effects&lt;/em&gt;. When you run a &lt;em&gt;ply&lt;/em&gt; function, everything happens inside that function, and nothing changes in your working environment (this is known as “functional programming”). In a &lt;code&gt;for&lt;/code&gt; loop, on the other hand, when you do something like &lt;code&gt;for(i in 1:10)&lt;/code&gt;, you get the leftover &lt;code&gt;i&lt;/code&gt; in your environment. This is considered bad practice sometimes. Having a bunch of temporary variables like &lt;code&gt;i&lt;/code&gt; lying around could cause problems in your code, especially if you use &lt;code&gt;i&lt;/code&gt; for something else later.&lt;/p&gt;
&lt;p&gt;I’ve seen arguments that &lt;code&gt;ply&lt;/code&gt; functions make for more expressive, easier to read code, but I’ve seen the same argument for &lt;code&gt;for&lt;/code&gt; loops. Once you are used to writing vectorized code in general, though, &lt;code&gt;for&lt;/code&gt; loops in R will can seem odd.&lt;/p&gt;
&lt;h2 id=&quot;so-when-might-for-loops-make-sense-over-vectorization&quot;&gt;So when might &lt;code&gt;for&lt;/code&gt; loops make sense over vectorization?&lt;/h2&gt;
&lt;p&gt;There are still situations that it may make sense to use &lt;code&gt;for&lt;/code&gt; loops instead of vectorized functions, though. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using functions that don’t take vector arguments&lt;/li&gt;
&lt;li&gt;Loops where each iteration is dependent on the results of previous iterations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the second case is tricky. In some cases where the &lt;em&gt;obvious&lt;/em&gt; implementation of an algorithm uses a &lt;code&gt;for&lt;/code&gt; loop, there’s a vectorized way around it. For instance, &lt;a href=&quot;https://www.stat.auckland.ac.nz/~ihaka/downloads/Taupo-handouts.pdf&quot;&gt;here is a good example of implementing a random walk using vectorized code&lt;/a&gt;. In these cases, you often want to call functions that are essentially C/FORTRAN implementations of loop operations to avoid the loop in R. Examples of such functions include &lt;code&gt;cumsum&lt;/code&gt; (cumulative sums), &lt;code&gt;rle&lt;/code&gt; (counting number of repeated value), and &lt;code&gt;ifelse&lt;/code&gt; (vectorized if…else statements).&lt;/p&gt;
&lt;p&gt;Your performance penalty for using a &lt;code&gt;for&lt;/code&gt; loop instead a vector will be small if the number of iterations is relatively small, and the functions called &lt;em&gt;inside&lt;/em&gt; your for loop are slow. In these cases, looping and overhead from function calls make up a small fraction of your computational time. It may make sense to use a &lt;code&gt;for&lt;/code&gt; loop in such cases, especially if they are more intuitive or easier to read &lt;em&gt;for you&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&quot;some-resources-on-vectorization&quot;&gt;Some resources on vectorization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Good discussion in a couple of &lt;a href=&quot;http://www.johnmyleswhite.com/notebook/2013/01/24/writing-better-statistical-programs-in-r/&quot;&gt;blog&lt;/a&gt; &lt;a href=&quot;http://www.johnmyleswhite.com/notebook/2013/12/22/the-relationship-between-vectorized-and-devectorized-code/&quot;&gt;posts&lt;/a&gt; by John Myles White.&lt;/li&gt;
&lt;li&gt;Some relevant chapters of Hadley Wickham’s Advanced R book: &lt;a href=&quot;http://adv-r.had.co.nz/Functionals.html&quot;&gt;Functionals&lt;/a&gt; and &lt;a href=&quot;http://adv-r.had.co.nz/Profiling.html#vectorise&quot;&gt;code profiling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vectorization is covered in chapters 3 and 4 of the classic text on R’s idiosyncrasies - &lt;a href=&quot;http://www.burns-stat.com/pages/Tutor/R_inferno.pdf&quot;&gt;The R Inferno&lt;/a&gt;, by Patrick Burns&lt;/li&gt;
&lt;li&gt;Here are a bunch of assorted blog posts with good examples of speeding up code with vectorization
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.r-bloggers.com/how-to-use-vectorization-to-streamline-simulations/&quot; class=&quot;uri&quot;&gt;http://www.r-bloggers.com/how-to-use-vectorization-to-streamline-simulations/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nesterko.com/blog/2011/04/29/drastic-r-speed-ups-via-vectorization-and-bug-fixes/&quot; class=&quot;uri&quot;&gt;http://nesterko.com/blog/2011/04/29/drastic-r-speed-ups-via-vectorization-and-bug-fixes/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/2014/04/a-look-a-r-vectorization-through-the-collatz-conjecture.html&quot; class=&quot;uri&quot;&gt;http://blog.revolutionanalytics.com/2014/04/a-look-a-r-vectorization-through-the-collatz-conjecture.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://rpubs.com/daspringate/vectorisation&quot; class=&quot;uri&quot;&gt;http://rpubs.com/daspringate/vectorisation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://quanttrader.info/public/FasterRCode.pdf&quot; class=&quot;uri&quot;&gt;http://quanttrader.info/public/FasterRCode.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 
</feed>